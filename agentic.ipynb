{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b3bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Sentence transformers for semantic similarity\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e8fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "GENAI_API_KEY = os.getenv(\"GENAI_API_KEY\")\n",
    "IMAGE_CAPTION_API_URL = \"https://api-inference.huggingface.co/models/Salesforce/blip-image-captioning-large\"\n",
    "\n",
    "# Initialize models\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=GENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d69c5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAnalysisAgent:\n",
    "    \"\"\"Agent responsible for extracting basic context from images.\"\"\"\n",
    "    \n",
    "    def __init__(self, hf_token: str):\n",
    "        self.headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "    \n",
    "    def extract_context(self, image_path: str) -> str:\n",
    "        \"\"\"Extract caption/context from an image using HuggingFace model.\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                image_bytes = image_file.read()\n",
    "            \n",
    "            response = requests.post(\n",
    "                IMAGE_CAPTION_API_URL, \n",
    "                headers=self.headers, \n",
    "                data=image_bytes\n",
    "            )\n",
    "            \n",
    "            if response.status_code != 200:\n",
    "                return f\"Error extracting context: {response.text}\"\n",
    "            \n",
    "            result = response.json()\n",
    "            return result[0]['generated_text']\n",
    "        except Exception as e:\n",
    "            return f\"Error processing image: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a8f0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryDetectionAgent:\n",
    "    \"\"\"Agent responsible for determining the post category.\"\"\"\n",
    "    \n",
    "    def __init__(self, model: SentenceTransformer):\n",
    "        self.model = model\n",
    "        self.categories = {\n",
    "            \"travel\": \"Traveling to beautiful places, taking trips, visiting beaches, sunsets over mountains, road journeys, flight experiences, exploring new cultures, or backpacking adventures\",\n",
    "            \"food\": \"Trying new dishes, gourmet meals, desserts like cake or pastries, dining out at restaurants, cooking recipes at home, drinking coffee, or exploring different cuisines\",\n",
    "            \"fashion\": \"Wearing trendy clothes, outfit styling, streetwear, fashion shows, seasonal wardrobes, latest trends in clothing and accessories, or personal fashion statements\",\n",
    "            \"fitness\": \"Daily gym workouts, home exercises, maintaining a healthy lifestyle, running, yoga sessions, lifting weights, staying fit or using fitness trackers\",\n",
    "            \"technology\": \"Cutting-edge gadgets, AI-powered systems, robots, computer hardware, futuristic innovations, coding, tech events, or anything related to digital transformation\",\n",
    "            \"sports\": \"Playing or watching football, cricket, basketball, sports events, Olympic games, fitness challenges, or athletes and tournaments\",\n",
    "            \"nature\": \"Beautiful landscapes, sunrise or sunset views, forests, mountains, oceans, animals in the wild, natural scenery, or environmental topics\",\n",
    "            \"education\": \"Learning new topics, studying, attending school or college, online courses, academic research, or reading books\",\n",
    "            \"entertainment\": \"Watching movies, web series, concerts, music festivals, celebrities, fun shows, or social media trends\"\n",
    "        }\n",
    "    \n",
    "    def detect_category(self, context: str) -> str:\n",
    "        \"\"\"Detect category based on semantic similarity.\"\"\"\n",
    "        input_embedding = self.model.encode(context, convert_to_tensor=True)\n",
    "        \n",
    "        best_category = \"general\"\n",
    "        best_score = -1\n",
    "        \n",
    "        for category, example_text in self.categories.items():\n",
    "            category_embedding = self.model.encode(example_text, convert_to_tensor=True)\n",
    "            similarity = util.cos_sim(input_embedding, category_embedding).item()\n",
    "            \n",
    "            if similarity > best_score:\n",
    "                best_score = similarity\n",
    "                best_category = category\n",
    "        \n",
    "        return best_category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2795d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextCombinationAgent:\n",
    "    \"\"\"Agent responsible for combining image context with user's advanced context.\"\"\"\n",
    "    \n",
    "    def combine_contexts(self, basic_context: str, advanced_context: str) -> str:\n",
    "        \"\"\"Merge the basic context from image with advanced context from user.\"\"\"\n",
    "        return f\"Basic Image Content: {basic_context}\\nUser Context: {advanced_context}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e30f34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalAgent:\n",
    "    \"\"\"Agent responsible for retrieving relevant captions from ChromaDB.\"\"\"\n",
    "    \n",
    "    def initialize_chroma(self, category: str):\n",
    "        \"\"\"Initialize ChromaDB for a specific category.\"\"\"\n",
    "        persist_directory = f\"./captions/{category}\"\n",
    "        os.makedirs(persist_directory, exist_ok=True)\n",
    "        return Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
    "    \n",
    "    def retrieve_captions(self, basic_context: str, advanced_context: str, category: str, k: int = 5) -> List[str]:\n",
    "        \"\"\"Retrieve relevant captions based on context.\"\"\"\n",
    "        vs = self.initialize_chroma(category)\n",
    "        combined_query = f\"{basic_context} {advanced_context}\"\n",
    "        results = vs.similarity_search(combined_query, k=k)\n",
    "        return [res.page_content for res in results]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ece28067",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptionGenerationAgent:\n",
    "    \"\"\"Agent responsible for generating the main caption.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def generate_caption(self, combined_context: str, retrieved_captions: List[str], category: str) -> str:\n",
    "        \"\"\"Generate a caption based on contexts and examples.\"\"\"\n",
    "        context_text = \"\\n\".join(retrieved_captions)\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"category\", \"context\", \"combined_context\"],\n",
    "            template=\"\"\"\n",
    "            You are a specialized Instagram caption generator for {category} posts.\n",
    "            \n",
    "            Here are some similar captions for reference:\n",
    "            {context}\n",
    "            \n",
    "            Based on this information:\n",
    "            {combined_context}\n",
    "            \n",
    "            Create an engaging, original Instagram caption (without hashtags) that captures the essence of the content.\n",
    "            Make it conversational, authentic, and attention-grabbing. Keep it under 200 characters.\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        formatted_prompt = prompt.format(\n",
    "            category=category,\n",
    "            context=context_text,\n",
    "            combined_context=combined_context\n",
    "        )\n",
    "        \n",
    "        response = self.llm.invoke(formatted_prompt)\n",
    "        return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a3b2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HashtagGenerationAgent:\n",
    "    \"\"\"Agent responsible for suggesting relevant hashtags.\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "    \n",
    "    def generate_hashtags(self, caption: str, category: str, retrieved_captions: List[str]) -> List[str]:\n",
    "        \"\"\"Generate relevant hashtags based on caption and category.\"\"\"\n",
    "        context_text = \"\\n\".join(retrieved_captions)\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            input_variables=[\"caption\", \"category\", \"context\"],\n",
    "            template=\"\"\"\n",
    "            You are a hashtag specialist for Instagram {category} posts.\n",
    "            \n",
    "            Here's the caption: {caption}\n",
    "            \n",
    "            Here are some example captions with their hashtags:\n",
    "            {context}\n",
    "            \n",
    "            Generate 5-7 relevant, trending hashtags for the caption.\n",
    "            Include both popular general hashtags and specific ones related to the content.\n",
    "            Return only the hashtags as a comma-separated list, without explanation or numbering.\n",
    "            Each hashtag should start with # and have no spaces.\n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "        formatted_prompt = prompt.format(\n",
    "            caption=caption,\n",
    "            category=category,\n",
    "            context=context_text\n",
    "        )\n",
    "        \n",
    "        response = self.llm.invoke(formatted_prompt)\n",
    "        # Process the response to extract just the hashtags\n",
    "        hashtags = [tag.strip() for tag in response.content.replace(\"\\n\", \" \").split(\",\") if tag.strip()]\n",
    "        return hashtags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "430a41ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputAssemblyAgent:\n",
    "    \"\"\"Agent responsible for combining caption and hashtags.\"\"\"\n",
    "    \n",
    "    def assemble_output(self, caption: str, hashtags: List[str]) -> str:\n",
    "        \"\"\"Combine caption and hashtags into final output.\"\"\"\n",
    "        hashtag_text = \" \".join(hashtags)\n",
    "        return f\"{caption}\\n\\n{hashtag_text}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "826d7958",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstagramCaptionGenerator:\n",
    "    \"\"\"Main coordinator for the Instagram caption generation workflow.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.image_agent = ImageAnalysisAgent(HF_TOKEN)\n",
    "        self.category_agent = CategoryDetectionAgent(sentence_model)\n",
    "        self.context_agent = ContextCombinationAgent()\n",
    "        self.retrieval_agent = RetrievalAgent()\n",
    "        self.caption_agent = CaptionGenerationAgent(llm)\n",
    "        self.hashtag_agent = HashtagGenerationAgent(llm)\n",
    "        self.output_agent = OutputAssemblyAgent()\n",
    "    \n",
    "    def generate(self, image_path: str, advanced_context: str) -> Dict[str, Any]:\n",
    "        \"\"\"Execute the full caption generation workflow.\"\"\"\n",
    "        # Step 1: Extract basic context from image\n",
    "        basic_context = self.image_agent.extract_context(image_path)\n",
    "        print(f\"Image Context: {basic_context}\")\n",
    "        \n",
    "        # Step 2: Determine post category\n",
    "        category = self.category_agent.detect_category(basic_context+advanced_context)\n",
    "        print(f\"Detected Category: {category}\")\n",
    "        \n",
    "        # Step 3: Combine contexts\n",
    "        combined_context = self.context_agent.combine_contexts(basic_context, advanced_context)\n",
    "        \n",
    "        # Step 4: Retrieve relevant captions\n",
    "        retrieved_captions = self.retrieval_agent.retrieve_captions(\n",
    "            basic_context, advanced_context, category\n",
    "        )\n",
    "        \n",
    "        # Step 5: Generate caption\n",
    "        caption = self.caption_agent.generate_caption(\n",
    "            combined_context, retrieved_captions, category\n",
    "        )\n",
    "        \n",
    "        # Step 6: Generate hashtags\n",
    "        hashtags = self.hashtag_agent.generate_hashtags(\n",
    "            caption, category, retrieved_captions\n",
    "        )\n",
    "        \n",
    "        # Step 7: Assemble final output\n",
    "        final_output = self.output_agent.assemble_output(caption, hashtags)\n",
    "        \n",
    "        return {\n",
    "            \"basic_context\": basic_context,\n",
    "            \"category\": category,\n",
    "            \"caption\": caption,\n",
    "            \"hashtags\": hashtags,\n",
    "            \"final_output\": final_output\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4a2577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions (from your original code)\n",
    "def load_json_data(json_file: str) -> List[Document]:\n",
    "    \"\"\"Load caption data from JSON file.\"\"\"\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    documents = []\n",
    "    for item in data:\n",
    "        caption = item.get(\"caption\", \"\")\n",
    "        hashtags = \" \".join(item.get(\"hashtags\", []))\n",
    "        content = f\"{caption} {hashtags}\"\n",
    "        documents.append(Document(page_content=content))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def update_chroma_db(category: str, json_file: str) -> None:\n",
    "    \"\"\"Update ChromaDB with new documents.\"\"\"\n",
    "    persist_directory = f\"./captions/{category}\"\n",
    "    os.makedirs(persist_directory, exist_ok=True)\n",
    "    \n",
    "    new_documents = load_json_data(json_file)\n",
    "    vs = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
    "    vs.add_documents(new_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b790fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_chroma_db(\"travel\", \"travel.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d795f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Context: araffe view of a beach with a lot of people on it\n",
      "Detected Category: travel\n",
      "\n",
      "=== Generated Instagram Post ===\n",
      "Hawaii family fun!  This beach was buzzing â€“ so many happy faces soaking up the sun.  Missing those ocean vibes already.\n",
      "\n",
      "#HawaiiFamilyFun #HawaiiBeach #OceanVibes #FamilyVacation #BeachLife #TravelHawaii #IslandLife\n"
     ]
    }
   ],
   "source": [
    "# Create caption generator\n",
    "generator = InstagramCaptionGenerator()\n",
    "\n",
    "# Generate caption for an image\n",
    "result = generator.generate(\n",
    "    image_path=\"/Users/aldrinvrodrigues/Engineering/SEM-6/Gen-AI/GenaiProject/testimage.jpeg\",\n",
    "    advanced_context=\"hawaii with family\"\n",
    ")\n",
    "\n",
    "print(\"\\n=== Generated Instagram Post ===\")\n",
    "print(result[\"final_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a015d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
